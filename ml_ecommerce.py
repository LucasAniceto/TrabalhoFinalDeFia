
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV, StratifiedKFold
from sklearn.ensemble import RandomForestRegressor, IsolationForest
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.feature_selection import SelectKBest, f_regression, RFECV
import xgboost as xgb
from scipy import stats
import logging
import warnings
import os
import json
import pickle
import schedule
import time
from datetime import datetime, timedelta
from typing import Tuple, Dict, List, Optional, Any
import hashlib

try:
    import kagglehub
    from kagglehub import KaggleDatasetAdapter
    KAGGLEHUB_AVAILABLE = True
except ImportError:
    KAGGLEHUB_AVAILABLE = False
    print("‚ö†Ô∏è kagglehub n√£o dispon√≠vel. Instale com: pip install kagglehub")

try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False
    print("‚ö†Ô∏è SHAP n√£o dispon√≠vel. Instale com: pip install shap")

try:
    from evidently import ColumnMapping
    from evidently.report import Report
    from evidently.metric_suite import MetricSuite
    from evidently.metrics import DatasetDriftMetric, DatasetMissingValuesMetric
    EVIDENTLY_AVAILABLE = True
except ImportError:
    EVIDENTLY_AVAILABLE = False
    print("‚ö†Ô∏è Evidently n√£o dispon√≠vel. Instale com: pip install evidently")

warnings.filterwarnings('ignore')

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ml_ecommerce.log'),
        logging.StreamHandler()
    ]
)


class Colors:
    RESET = '\033[0m'
    BOLD = '\033[1m'
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    PURPLE = '\033[95m'
    CYAN = '\033[96m'

def print_header(text):
    print(f"\n{Colors.CYAN}{'='*80}{Colors.RESET}")
    print(f"{Colors.CYAN}{Colors.BOLD}{text:^80}{Colors.RESET}")
    print(f"{Colors.CYAN}{'='*80}{Colors.RESET}")

def print_section(text):
    print(f"\n{Colors.YELLOW}{Colors.BOLD}üîÑ {text}{Colors.RESET}")
    print(f"{Colors.BLUE}{'‚îÄ'*60}{Colors.RESET}")


def baixar_dados_kaggle():
    """Baixa o dataset do Kaggle usando kagglehub"""
    print_section("BAIXANDO DATASETS DO KAGGLE")
    
    if not KAGGLEHUB_AVAILABLE:
        print(f"{Colors.RED}‚ùå kagglehub n√£o est√° dispon√≠vel. Instale com: pip install kagglehub{Colors.RESET}")
        return None
    
    try:
        arquivos_dataset = {
            'orders': 'olist_orders_dataset.csv',
            'order_items': 'olist_order_items_dataset.csv', 
            'products': 'olist_products_dataset.csv',
            'sellers': 'olist_sellers_dataset.csv',
            'customers': 'olist_customers_dataset.csv',
            'reviews': 'olist_order_reviews_dataset.csv',
            'category_translation': 'product_category_name_translation.csv'
        }
        
        datasets = {}
        dataset_id = "olistbr/brazilian-ecommerce"
        
        print(f"   üì• Baixando dataset: {dataset_id}")
        
        for nome, arquivo in arquivos_dataset.items():
            try:
                print(f"   üîÑ Baixando {arquivo}...")
                df = kagglehub.load_dataset(
                    KaggleDatasetAdapter.PANDAS,
                    dataset_id,
                    arquivo
                )
                datasets[nome] = df
                print(f"   ‚úÖ {nome}: {df.shape} - {arquivo}")
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erro ao baixar {arquivo}: {e}")
                try:
                    print(f"   üîÑ Tentativa alternativa para {arquivo}...")
                    caminho_arquivo = kagglehub.dataset_download(dataset_id)
                    caminho_completo = os.path.join(caminho_arquivo, arquivo)
                    if os.path.exists(caminho_completo):
                        df = pd.read_csv(caminho_completo)
                        datasets[nome] = df
                        print(f"   ‚úÖ {nome}: {df.shape} - {arquivo} (m√©todo alternativo)")
                    else:
                        print(f"   ‚ùå {nome}: Arquivo n√£o encontrado ap√≥s download - {arquivo}")
                except Exception as e2:
                    print(f"   ‚ùå {nome}: Falha total ao baixar - {arquivo}: {e2}")
        
        if datasets:
            print(f"   üéâ {len(datasets)} datasets baixados com sucesso!")
            return datasets
        else:
            print(f"   ‚ùå Nenhum dataset foi baixado com sucesso")
            return None
            
    except Exception as e:
        print(f"{Colors.RED}‚ùå Erro geral ao baixar dados do Kaggle: {e}{Colors.RESET}")
        print(f"{Colors.YELLOW}üí° Verifique se voc√™ tem acesso ao Kaggle API configurado{Colors.RESET}")
        print(f"{Colors.YELLOW}   Configure com: kaggle auth login{Colors.RESET}")
        return None


def carregar_dados(caminho_base=None, usar_kaggle=True):
    """Carrega todos os datasets do Olist - do Kaggle ou local"""
    
    if usar_kaggle:
        print(f"{Colors.CYAN}üåê Tentando baixar dados do Kaggle...{Colors.RESET}")
        datasets = baixar_dados_kaggle()
        if datasets:
            return datasets
        else:
            print(f"{Colors.YELLOW}‚ö†Ô∏è Falha ao baixar do Kaggle. Tentando carregar arquivos locais...{Colors.RESET}")
    
    if not caminho_base:
        print(f"{Colors.RED}‚ùå Caminho base n√£o fornecido para arquivos locais{Colors.RESET}")
        return None
        
    print_section("CARREGANDO DATASETS LOCAIS")
    
    try:
        arquivos = {
            'orders': 'olist_orders_dataset.csv',
            'order_items': 'olist_order_items_dataset.csv',
            'products': 'olist_products_dataset.csv',
            'sellers': 'olist_sellers_dataset.csv',
            'customers': 'olist_customers_dataset.csv',
            'reviews': 'olist_order_reviews_dataset.csv',
            'category_translation': 'product_category_name_translation.csv'
        }
        
        datasets = {}
        
        for nome, arquivo in arquivos.items():
            caminho_completo = os.path.join(caminho_base, arquivo)
            if os.path.exists(caminho_completo):
                datasets[nome] = pd.read_csv(caminho_completo)
                print(f"   ‚úÖ {nome}: {datasets[nome].shape} - {arquivo}")
            else:
                print(f"   ‚ùå {nome}: Arquivo n√£o encontrado - {arquivo}")
        
        return datasets
    
    except Exception as e:
        print(f"{Colors.RED}‚ùå Erro ao carregar dados: {e}{Colors.RESET}")
        return None

def juntar_datasets(datasets):
    """Junta todos os datasets em um dataset principal"""
    print_section("JUNTANDO DATASETS")
    
    df_main = datasets['order_items'].copy()
    print(f"   üìä Base (order_items): {df_main.shape}")
    
    if 'products' in datasets:
        df_main = df_main.merge(datasets['products'], on='product_id', how='left')
        print(f"   üìä + products: {df_main.shape}")
    
    if 'category_translation' in datasets:
        df_main = df_main.merge(datasets['category_translation'], 
                               on='product_category_name', how='left')
        print(f"   üìä + category_translation: {df_main.shape}")
    
    if 'orders' in datasets:
        df_main = df_main.merge(datasets['orders'][['order_id', 'customer_id', 'order_status',
                                                   'order_purchase_timestamp']], 
                               on='order_id', how='left')
        print(f"   üìä + orders: {df_main.shape}")
    
    if 'customers' in datasets:
        df_main = df_main.merge(datasets['customers'][['customer_id', 'customer_city',
                                                      'customer_state']], 
                               on='customer_id', how='left')
        print(f"   üìä + customers: {df_main.shape}")
    
    if 'sellers' in datasets:
        df_main = df_main.merge(datasets['sellers'][['seller_id', 'seller_city', 
                                                    'seller_state']], 
                               on='seller_id', how='left')
        print(f"   üìä + sellers: {df_main.shape}")
    
    if 'reviews' in datasets:
        reviews_agg = datasets['reviews'].groupby('order_id').agg({
            'review_score': 'mean',
            'review_id': 'count'
        }).rename(columns={'review_id': 'num_reviews'}).reset_index()
        
        df_main = df_main.merge(reviews_agg, on='order_id', how='left')
        print(f"   üìä + reviews (agregadas): {df_main.shape}")
    
    print(f"\n   üéØ Dataset final: {df_main.shape}")
    return df_main


def detectar_outliers_avancado(df, metodo='isolation_forest'):
    """Detecta outliers usando m√©todos estat√≠sticos avan√ßados"""
    logging.info(f"Detectando outliers usando m√©todo: {metodo}")
    
    if metodo == 'isolation_forest':
        features_numericas = ['price', 'freight_value', 'product_weight_g', 
                             'product_length_cm', 'product_height_cm', 'product_width_cm']
        features_disponiveis = [f for f in features_numericas if f in df.columns]
        
        if len(features_disponiveis) > 0:
            X_outliers = df[features_disponiveis].fillna(df[features_disponiveis].median())
            
            iso_forest = IsolationForest(contamination=0.05, random_state=42, n_jobs=-1)
            outliers_pred = iso_forest.fit_predict(X_outliers)
            
            outliers_mask = outliers_pred == 1
            
            print(f"   üîç Isolation Forest removeu {len(df) - outliers_mask.sum()} outliers")
            return df[outliers_mask].copy()
    
    Q1 = df['price'].quantile(0.01)
    Q3 = df['price'].quantile(0.99)
    df_filtered = df[(df['price'] >= Q1) & (df['price'] <= Q3)]
    print(f"   üìä M√©todo estat√≠stico removeu {len(df) - len(df_filtered)} outliers")
    
    return df_filtered

def limpar_dados(df):
    """Limpa e prepara os dados para an√°lise com m√©todos avan√ßados"""
    print_section("LIMPEZA E PREPARA√á√ÉO DOS DADOS")
    logging.info("Iniciando limpeza de dados")
    
    df_clean = df.copy()
    
    df_clean = df_clean[df_clean['order_status'] == 'delivered'].copy()
    print(f"   üì¶ Apenas pedidos entregues: {df_clean.shape}")
    logging.info(f"Filtrados pedidos entregues: {df_clean.shape}")
    
    colunas_criticas = ['price', 'product_id']
    df_clean = df_clean.dropna(subset=colunas_criticas)
    print(f"   üßπ Ap√≥s remover NAs cr√≠ticos: {df_clean.shape}")
    
    df_clean = detectar_outliers_avancado(df_clean, metodo='isolation_forest')
    print(f"   üìä Ap√≥s detec√ß√£o avan√ßada de outliers: {df_clean.shape}")
    
    colunas_numericas = ['review_score', 'num_reviews', 'product_weight_g', 
                        'product_length_cm', 'product_height_cm', 'product_width_cm']
    
    for coluna in colunas_numericas:
        if coluna in df_clean.columns:
            if coluna == 'num_reviews':
                df_clean[coluna].fillna(0, inplace=True)
            elif coluna == 'review_score':
                if 'product_category_name' in df_clean.columns:
                    df_clean[coluna] = df_clean.groupby('product_category_name')[coluna].transform(
                        lambda x: x.fillna(x.median()))
                df_clean[coluna].fillna(df_clean[coluna].median(), inplace=True)
            else:
                df_clean[coluna].fillna(df_clean[coluna].median(), inplace=True)
    
    print(f"   ‚úÖ Limpeza conclu√≠da: {df_clean.shape}")
    logging.info(f"Limpeza conclu√≠da. Shape final: {df_clean.shape}")
    return df_clean

def engenharia_features(df):
    """Cria novas features para melhorar o modelo"""
    print_section("ENGENHARIA DE FEATURES")
    
    df_features = df.copy()
    
    df_features['order_purchase_timestamp'] = pd.to_datetime(df_features['order_purchase_timestamp'])
    df_features['order_month'] = df_features['order_purchase_timestamp'].dt.month
    df_features['order_dayofweek'] = df_features['order_purchase_timestamp'].dt.dayofweek
    df_features['order_hour'] = df_features['order_purchase_timestamp'].dt.hour
    df_features['is_weekend'] = (df_features['order_dayofweek'] >= 5).astype(int)
    
    df_features['product_volume'] = (df_features['product_length_cm'] * 
                                   df_features['product_height_cm'] * 
                                   df_features['product_width_cm'])
    df_features['product_volume'] = df_features['product_volume'].fillna(
        df_features['product_volume'].median())
    
    df_features['density'] = df_features['product_weight_g'] / (df_features['product_volume'] + 1)
    
    df_features['same_state'] = (df_features['customer_state'] == 
                               df_features['seller_state']).astype(int)
    
    df_features['quality_score'] = (df_features['review_score'] * 
                                  np.log1p(df_features['num_reviews']))
    
    df_features['month_sin'] = np.sin(2 * np.pi * df_features['order_month'] / 12)
    df_features['month_cos'] = np.cos(2 * np.pi * df_features['order_month'] / 12)
    
    le_category = LabelEncoder()
    le_customer_state = LabelEncoder()
    le_seller_state = LabelEncoder()
    
    df_features['product_category_name'].fillna('unknown', inplace=True)
    df_features['customer_state'].fillna('unknown', inplace=True)
    df_features['seller_state'].fillna('unknown', inplace=True)
    
    df_features['category_encoded'] = le_category.fit_transform(df_features['product_category_name'])
    df_features['customer_state_encoded'] = le_customer_state.fit_transform(df_features['customer_state'])
    df_features['seller_state_encoded'] = le_seller_state.fit_transform(df_features['seller_state'])
    
    product_stats = df_features.groupby('product_category_name').agg({
        'price': ['mean', 'std', 'count'],
        'review_score': 'mean'
    }).round(2)
    
    product_stats.columns = ['category_price_mean', 'category_price_std', 
                           'category_count', 'category_review_mean']
    product_stats = product_stats.reset_index()
    
    df_features = df_features.merge(product_stats, on='product_category_name', how='left')
    
    print(f"   ‚úÖ Features criadas. Shape final: {df_features.shape}")
    
    return df_features, le_category, le_customer_state, le_seller_state


def selecionar_features_shap(modelo, X_sample, y_sample, feature_names, max_features=15):
    """Seleciona features usando import√¢ncia SHAP"""
    if not SHAP_AVAILABLE:
        logging.warning("SHAP n√£o dispon√≠vel. Usando import√¢ncia padr√£o do modelo.")
        return None, None
    
    try:
        print(f"   üîç Calculando import√¢ncia SHAP (amostra de {len(X_sample)} registros)...")
        
        if hasattr(modelo, 'estimators_'):
            explainer = shap.TreeExplainer(modelo)
        else:
            explainer = shap.Explainer(modelo)
        
        sample_size = min(100, len(X_sample))
        if hasattr(X_sample, 'sample'):
            X_shap_sample = X_sample.sample(n=sample_size, random_state=42).values
        else:
            sample_indices = np.random.choice(len(X_sample), sample_size, replace=False)
            X_shap_sample = X_sample[sample_indices]
        
        print(f"   üîç Amostra SHAP: {X_shap_sample.shape}")
        
        shap_values = explainer.shap_values(X_shap_sample)
        
        if isinstance(shap_values, list):
            shap_values = shap_values[0]
        
        feature_importance = np.mean(np.abs(shap_values), axis=0)
        
        shap_importance = pd.DataFrame({
            'Feature': feature_names,
            'SHAP_Importance': feature_importance
        }).sort_values('SHAP_Importance', ascending=False)
        
        top_features = shap_importance.head(max_features)['Feature'].tolist()
        features_mask = [f in top_features for f in feature_names]
        
        print(f"   üéØ SHAP selecionou {len(top_features)} features")
        print(f"   üìä Top 5 features SHAP:")
        for i, row in shap_importance.head(5).iterrows():
            print(f"      {row['Feature']}: {row['SHAP_Importance']:.4f}")
        
        return features_mask, shap_importance
    
    except Exception as e:
        logging.error(f"Erro no c√°lculo SHAP: {e}")
        return None, None

def selecionar_features_automatico(X, y, metodo='rfe'):
    """Seleciona features automaticamente usando diferentes m√©todos"""
    logging.info(f"Selecionando features usando m√©todo: {metodo}")
    
    if metodo == 'shap' and SHAP_AVAILABLE:
        rf_temp = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        rf_temp.fit(X, y)
        
        feature_names = [f'feature_{i}' for i in range(X.shape[1])]
        
        features_mask, shap_importance = selecionar_features_shap(
            rf_temp, X, y, feature_names, max_features=15
        )
        
        if features_mask is not None:
            if hasattr(X, 'iloc'):
                X_selected = X.iloc[:, features_mask]
            else:
                X_selected = X[:, features_mask]
            print(f"   üéØ SHAP selecionou {X_selected.shape[1]} de {X.shape[1]} features")
            return X_selected, np.array(features_mask), None
    
    elif metodo == 'rfe':
        rf_selector = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        selector = RFECV(estimator=rf_selector, step=1, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)
        X_selected = selector.fit_transform(X, y)
        
        features_selecionadas = selector.support_
        print(f"   üéØ RFE selecionou {X_selected.shape[1]} de {X.shape[1]} features")
        
        return X_selected, features_selecionadas, selector
    
    elif metodo == 'kbest':
        k_features = min(15, X.shape[1])
        selector = SelectKBest(score_func=f_regression, k=k_features)
        X_selected = selector.fit_transform(X, y)
        
        features_selecionadas = selector.get_support()
        print(f"   üéØ K-Best selecionou {X_selected.shape[1]} features")
        
        return X_selected, features_selecionadas, selector
    
    return X, np.ones(X.shape[1], dtype=bool), None

def criar_estratos_preco(y, n_estratos=5):
    """Cria estratos baseados em faixas de pre√ßo para valida√ß√£o estratificada"""
    try:
        percentis = np.linspace(0, 100, n_estratos + 1)
        limites = np.percentile(y, percentis)
        
        estratos = np.digitize(y, limites[1:-1])
        
        estratos = np.clip(estratos, 0, n_estratos - 1)
        
        return estratos
    except Exception as e:
        logging.warning(f"Erro ao criar estratos: {e}. Usando estratifica√ß√£o simples.")
        q25, q50, q75 = np.percentile(y, [25, 50, 75])
        estratos = np.where(y <= q25, 0, 
                           np.where(y <= q50, 1,
                                   np.where(y <= q75, 2, 3)))
        return estratos

def validacao_cruzada_estratificada(X, y, modelo, n_splits=5):
    """Realiza valida√ß√£o cruzada estratificada por faixa de pre√ßo"""
    print(f"   üìä Realizando valida√ß√£o cruzada estratificada com {n_splits} splits...")
    
    estratos = criar_estratos_preco(y, n_estratos=5)
    
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    scores_mae = []
    scores_rmse = []
    scores_r2 = []
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(X, estratos)):
        X_train_fold, X_val_fold = X[train_idx], X[val_idx]
        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]
        
        estratos_train = estratos[train_idx]
        estratos_val = estratos[val_idx]
        
        print(f"      Fold {fold+1}: Train estratos {np.bincount(estratos_train)}, "
              f"Val estratos {np.bincount(estratos_val)}")
        
        modelo_fold = modelo.__class__(**modelo.get_params())
        modelo_fold.fit(X_train_fold, y_train_fold)
        
        y_pred_fold = modelo_fold.predict(X_val_fold)
        
        mae_fold = mean_absolute_error(y_val_fold, y_pred_fold)
        rmse_fold = np.sqrt(mean_squared_error(y_val_fold, y_pred_fold))
        r2_fold = r2_score(y_val_fold, y_pred_fold)
        
        scores_mae.append(mae_fold)
        scores_rmse.append(rmse_fold)
        scores_r2.append(r2_fold)
        
        print(f"         M√©tricas: MAE={mae_fold:.2f}, RMSE={rmse_fold:.2f}, R¬≤={r2_fold:.4f}")
    
    print(f"   üìä CV Estratificada - M√©dias: MAE={np.mean(scores_mae):.2f}¬±{np.std(scores_mae):.2f}")
    print(f"                                RMSE={np.mean(scores_rmse):.2f}¬±{np.std(scores_rmse):.2f}")
    print(f"                                R¬≤={np.mean(scores_r2):.4f}¬±{np.std(scores_r2):.4f}")
    
    return {
        'mae_mean': np.mean(scores_mae), 'mae_std': np.std(scores_mae),
        'rmse_mean': np.mean(scores_rmse), 'rmse_std': np.std(scores_rmse),
        'r2_mean': np.mean(scores_r2), 'r2_std': np.std(scores_r2),
        'estratos_info': {
            'n_estratos': len(np.unique(estratos)),
            'distribuicao': np.bincount(estratos).tolist()
        }
    }

def validacao_cruzada_temporal(X, y, modelo, n_splits=5):
    """Realiza valida√ß√£o cruzada temporal respeitando ordem cronol√≥gica"""
    tscv = TimeSeriesSplit(n_splits=n_splits)
    
    scores_mae = []
    scores_rmse = []
    scores_r2 = []
    
    print(f"   ‚è∞ Realizando valida√ß√£o cruzada temporal com {n_splits} splits...")
    
    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
        X_train_fold, X_val_fold = X[train_idx], X[val_idx]
        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]
        
        modelo_fold = modelo.__class__(**modelo.get_params())
        modelo_fold.fit(X_train_fold, y_train_fold)
        
        y_pred_fold = modelo_fold.predict(X_val_fold)
        
        mae_fold = mean_absolute_error(y_val_fold, y_pred_fold)
        rmse_fold = np.sqrt(mean_squared_error(y_val_fold, y_pred_fold))
        r2_fold = r2_score(y_val_fold, y_pred_fold)
        
        scores_mae.append(mae_fold)
        scores_rmse.append(rmse_fold)
        scores_r2.append(r2_fold)
        
        print(f"      Fold {fold+1}: MAE={mae_fold:.2f}, RMSE={rmse_fold:.2f}, R¬≤={r2_fold:.4f}")
    
    print(f"   üìä CV Temporal - M√©dias: MAE={np.mean(scores_mae):.2f}¬±{np.std(scores_mae):.2f}")
    print(f"                           RMSE={np.mean(scores_rmse):.2f}¬±{np.std(scores_rmse):.2f}")
    print(f"                           R¬≤={np.mean(scores_r2):.4f}¬±{np.std(scores_r2):.4f}")
    
    return {
        'mae_mean': np.mean(scores_mae), 'mae_std': np.std(scores_mae),
        'rmse_mean': np.mean(scores_rmse), 'rmse_std': np.std(scores_rmse),
        'r2_mean': np.mean(scores_r2), 'r2_std': np.std(scores_r2)
    }

def otimizar_hiperparametros(X_train, y_train, modelo_tipo='random_forest'):
    """Otimiza hiperpar√¢metros usando Grid Search"""
    print(f"   üîß Otimizando hiperpar√¢metros para {modelo_tipo}...")
    logging.info(f"Iniciando otimiza√ß√£o de hiperpar√¢metros para {modelo_tipo}")
    
    if modelo_tipo == 'random_forest':
        modelo = RandomForestRegressor(random_state=42, n_jobs=-1)
        param_grid = {
            'n_estimators': [100, 200],
            'max_depth': [20, 25, 30],
            'min_samples_split': [2, 3],
            'min_samples_leaf': [1, 2],
            'max_features': ['sqrt', 'log2']
        }
        
    elif modelo_tipo == 'xgboost':
        modelo = xgb.XGBRegressor(random_state=42, n_jobs=-1)
        param_grid = {
            'n_estimators': [100, 200],
            'max_depth': [6, 8, 10],
            'learning_rate': [0.05, 0.1],
            'subsample': [0.8, 0.9],
            'colsample_bytree': [0.8, 0.9]
        }
    
    grid_search = GridSearchCV(
        estimator=modelo,
        param_grid=param_grid,
        cv=3,
        scoring='neg_mean_squared_error',
        n_jobs=-1,
        verbose=0
    )
    
    grid_search.fit(X_train, y_train)
    
    print(f"   ‚úÖ Melhores par√¢metros encontrados:")
    for param, value in grid_search.best_params_.items():
        print(f"      {param}: {value}")
    
    logging.info(f"Melhores par√¢metros: {grid_search.best_params_}")
    
    return grid_search.best_estimator_

def analisar_residuos(y_true, y_pred, nome_modelo):
    """Analisa res√≠duos do modelo para diagn√≥sticos"""
    residuos = y_true - y_pred
    
    mean_residuo = np.mean(residuos)
    std_residuo = np.std(residuos)
    
    if len(residuos) < 5000:
        shapiro_stat, shapiro_p = stats.shapiro(residuos[:5000])
        normalidade = "Normal" if shapiro_p > 0.05 else "N√£o Normal"
    else:
        normalidade = "Amostra muito grande para teste"
    
    residuos_abs = np.abs(residuos)
    correlation_het = np.corrcoef(y_pred, residuos_abs)[0, 1]
    heterocedasticidade = "Presente" if abs(correlation_het) > 0.1 else "Ausente"
    
    print(f"   üìä An√°lise de Res√≠duos - {nome_modelo}:")
    print(f"      M√©dia dos res√≠duos: {mean_residuo:.4f}")
    print(f"      Desvio padr√£o: {std_residuo:.2f}")
    print(f"      Normalidade: {normalidade}")
    print(f"      Heterocedasticidade: {heterocedasticidade}")
    
    return {
        'mean_residuo': mean_residuo,
        'std_residuo': std_residuo,
        'normalidade': normalidade,
        'heterocedasticidade': heterocedasticidade
    }

def calcular_intervalos_predicao(modelo, X_sample, dados_categoria=None, nivel_confianca=0.95):
    """Calcula intervalos de predi√ß√£o mais robustos"""
    if hasattr(modelo, 'estimators_'):
        tree_predictions = np.array([tree.predict(X_sample) for tree in modelo.estimators_])
        
        alpha = 1 - nivel_confianca
        lower_percentile = (alpha/2) * 100
        upper_percentile = (1 - alpha/2) * 100
        
        prediction_mean = np.mean(tree_predictions, axis=0)
        prediction_lower = np.percentile(tree_predictions, lower_percentile, axis=0)
        prediction_upper = np.percentile(tree_predictions, upper_percentile, axis=0)
        
        return prediction_mean, prediction_lower, prediction_upper
    
    else:
        prediction = modelo.predict(X_sample)
        
        if dados_categoria is not None:
            market_std = dados_categoria['price'].std()
            market_mean = dados_categoria['price'].mean()
            
            relative_std = market_std / market_mean
            prediction_std = prediction * relative_std
            
            z_score = 1.96 if nivel_confianca == 0.95 else 2.58
            margin = prediction_std * z_score
        else:
            margin = prediction * 0.1
        
        return prediction, prediction - margin, prediction + margin


def calcular_drift_estatistico(dados_referencia, dados_atuais, threshold=0.05):
    """Calcula drift usando testes estat√≠sticos"""
    drift_results = {}
    
    for coluna in dados_referencia.columns:
        if dados_referencia[coluna].dtype in ['int64', 'float64']:
            try:
                statistic, p_value = stats.ks_2samp(
                    dados_referencia[coluna].dropna(), 
                    dados_atuais[coluna].dropna()
                )
                
                drift_results[coluna] = {
                    'test': 'ks_test',
                    'statistic': statistic,
                    'p_value': p_value,
                    'drift_detected': p_value < threshold,
                    'severity': 'high' if p_value < 0.001 else 'medium' if p_value < 0.01 else 'low'
                }
            except Exception as e:
                drift_results[coluna] = {
                    'test': 'ks_test',
                    'error': str(e),
                    'drift_detected': False
                }
    
    return drift_results

def monitorar_drift_dados(dados_referencia, dados_atuais, features_importantes=None):
    """Monitora drift nos dados usando m√∫ltiplas abordagens"""
    print_section("MONITORAMENTO DE DRIFT DOS DADOS")
    
    drift_stats = calcular_drift_estatistico(dados_referencia, dados_atuais)
    
    drift_evidently = None
    if EVIDENTLY_AVAILABLE:
        try:
            reference_data = dados_referencia.select_dtypes(include=[np.number])
            current_data = dados_atuais.select_dtypes(include=[np.number])
            
            common_columns = reference_data.columns.intersection(current_data.columns)
            reference_data = reference_data[common_columns]
            current_data = current_data[common_columns]
            
            drift_report = Report(metrics=[
                DatasetDriftMetric(),
                DatasetMissingValuesMetric()
            ])
            
            drift_report.run(
                reference_data=reference_data,
                current_data=current_data
            )
            
            drift_report.save_html("drift_report.html")
            print(f"   üìä Relat√≥rio Evidently salvo em: drift_report.html")
            
            drift_evidently = "Relat√≥rio gerado com sucesso"
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Erro no Evidently: {e}")
            drift_evidently = f"Erro: {e}"
    
    print(f"\n   üìä RESULTADOS DO MONITORAMENTO:")
    
    drifts_detectados = 0
    features_com_drift = []
    
    for feature, result in drift_stats.items():
        if result.get('drift_detected', False):
            drifts_detectados += 1
            features_com_drift.append(feature)
            severity = result.get('severity', 'unknown')
            p_value = result.get('p_value', 0)
            
            icon = "üî¥" if severity == 'high' else "üü°" if severity == 'medium' else "üü¢"
            print(f"   {icon} {feature}: p-value={p_value:.6f} ({severity})")
    
    if drifts_detectados == 0:
        print(f"   ‚úÖ Nenhum drift significativo detectado")
    else:
        print(f"   ‚ö†Ô∏è {drifts_detectados} features com drift detectado")
        
        if features_importantes:
            drift_importantes = [f for f in features_com_drift if f in features_importantes]
            if drift_importantes:
                print(f"   üö® Features importantes com drift: {drift_importantes}")
    
    total_features = len(drift_stats)
    drift_score = (drifts_detectados / total_features) * 100 if total_features > 0 else 0
    
    print(f"\n   üìà SCORE GERAL DE DRIFT: {drift_score:.1f}%")
    
    if drift_score > 30:
        print(f"   üö® ALERTA: Alto n√≠vel de drift detectado - considere retreinar o modelo")
    elif drift_score > 15:
        print(f"   ‚ö†Ô∏è ATEN√á√ÉO: Drift moderado detectado - monitorar de perto")
    else:
        print(f"   ‚úÖ N√≠vel de drift aceit√°vel")
    
    return {
        'drift_score': drift_score,
        'features_com_drift': features_com_drift,
        'total_features': total_features,
        'drift_details': drift_stats,
        'evidently_status': drift_evidently,
        'recomendacao': 'retreinar' if drift_score > 30 else 'monitorar' if drift_score > 15 else 'ok'
    }

def salvar_dados_referencia(dados, caminho='dados_referencia.pkl'):
    """Salva dados de refer√™ncia para monitoramento futuro"""
    try:
        with open(caminho, 'wb') as f:
            pickle.dump(dados, f)
        print(f"   üíæ Dados de refer√™ncia salvos em: {caminho}")
        return True
    except Exception as e:
        print(f"   ‚ùå Erro ao salvar dados de refer√™ncia: {e}")
        return False

def carregar_dados_referencia(caminho='dados_referencia.pkl'):
    """Carrega dados de refer√™ncia para compara√ß√£o"""
    try:
        with open(caminho, 'rb') as f:
            dados = pickle.load(f)
        print(f"   üìÇ Dados de refer√™ncia carregados de: {caminho}")
        return dados
    except Exception as e:
        print(f"   ‚ö†Ô∏è N√£o foi poss√≠vel carregar dados de refer√™ncia: {e}")
        return None


class ModeloRetreinamento:
    """Classe para gerenciar retreinamento autom√°tico do modelo"""
    
    def __init__(self, caminho_modelo='modelo_pricing.pkl', caminho_config='config_retreinamento.json'):
        self.caminho_modelo = caminho_modelo
        self.caminho_config = caminho_config
        self.config = self.carregar_config()
    
    def carregar_config(self):
        """Carrega configura√ß√µes de retreinamento"""
        config_default = {
            'threshold_drift': 20,
            'min_dias_entre_treinos': 7,
            'min_novos_dados': 1000,
            'backup_modelos': True,
            'notificar_retreino': True
        }
        
        try:
            with open(self.caminho_config, 'r') as f:
                config_usuario = json.load(f)
            config_default.update(config_usuario)
        except FileNotFoundError:
            with open(self.caminho_config, 'w') as f:
                json.dump(config_default, f, indent=2)
            print(f"   üìù Arquivo de configura√ß√£o criado: {self.caminho_config}")
        
        return config_default
    
    def verificar_necessidade_retreino(self, drift_score, novos_dados, ultimo_treino=None):
        """Verifica se √© necess√°rio retreinar o modelo"""
        criterios = {
            'drift_alto': drift_score > self.config['threshold_drift'],
            'dados_suficientes': len(novos_dados) >= self.config['min_novos_dados'],
            'tempo_adequado': True
        }
        
        if ultimo_treino:
            dias_desde_ultimo = (datetime.now() - ultimo_treino).days
            criterios['tempo_adequado'] = dias_desde_ultimo >= self.config['min_dias_entre_treinos']
        
        necessita_retreino = all(criterios.values())
        
        print(f"   üîç CRIT√âRIOS PARA RETREINAMENTO:")
        for criterio, valor in criterios.items():
            icon = "‚úÖ" if valor else "‚ùå"
            print(f"      {icon} {criterio}: {valor}")
        
        return necessita_retreino, criterios
    
    def salvar_modelo(self, modelo, scaler, features, metadata=None):
        """Salva modelo treinado com metadata"""
        modelo_data = {
            'modelo': modelo,
            'scaler': scaler,
            'features': features,
            'timestamp': datetime.now(),
            'metadata': metadata or {}
        }
        
        if self.config['backup_modelos'] and os.path.exists(self.caminho_modelo):
            backup_path = f"{self.caminho_modelo}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            os.rename(self.caminho_modelo, backup_path)
            print(f"   üì¶ Backup do modelo anterior: {backup_path}")
        
        with open(self.caminho_modelo, 'wb') as f:
            pickle.dump(modelo_data, f)
        
        print(f"   üíæ Modelo salvo: {self.caminho_modelo}")
        return True
    
    def carregar_modelo(self):
        """Carrega modelo salvo"""
        try:
            with open(self.caminho_modelo, 'rb') as f:
                modelo_data = pickle.load(f)
            
            print(f"   üìÇ Modelo carregado de: {self.caminho_modelo}")
            print(f"   üìÖ Treinado em: {modelo_data['timestamp']}")
            
            return modelo_data
        except Exception as e:
            print(f"   ‚ùå Erro ao carregar modelo: {e}")
            return None

def agendar_retreinamento_automatico():
    """Agenda verifica√ß√µes peri√≥dicas para retreinamento"""
    def verificar_e_retreinar():
        print_section("VERIFICA√á√ÉO AUTOM√ÅTICA DE RETREINAMENTO")
        print(f"   üïê Executado em: {datetime.now()}")
        
        
        print("   ‚úÖ Verifica√ß√£o conclu√≠da")
    
    schedule.every().day.at("02:00").do(verificar_e_retreinar)
    
    print("   ‚è∞ Retreinamento autom√°tico agendado para 02:00 diariamente")
    print("   üí° Para ativar, execute: python -c 'import schedule; import time; while True: schedule.run_pending(); time.sleep(60)'")

def treinar_modelos_multiplos(df):
    """Treina m√∫ltiplos modelos e compara performance"""
    print_section("TREINAMENTO DE M√öLTIPLOS MODELOS COM OTIMIZA√á√ÉO")
    logging.info("Iniciando treinamento de m√∫ltiplos modelos")
    
    feature_columns = [
        'freight_value', 'product_weight_g', 'product_length_cm', 
        'product_height_cm', 'product_width_cm', 'product_volume',
        'density', 'review_score', 'num_reviews', 'quality_score',
        'order_month', 'order_dayofweek', 'order_hour', 'is_weekend',
        'month_sin', 'month_cos', 'same_state',
        'category_encoded', 'customer_state_encoded', 'seller_state_encoded',
        'category_price_mean', 'category_price_std', 'category_count',
        'category_review_mean'
    ]
    
    features_disponiveis = [f for f in feature_columns if f in df.columns]
    print(f"   üìä Features dispon√≠veis: {len(features_disponiveis)}")
    
    X = df[features_disponiveis]
    y = df['price']
    
    X = X.replace([np.inf, -np.inf], np.nan)
    X = X.fillna(X.median())
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"   üéØ Treino: {X_train.shape[0]} amostras")
    print(f"   üéØ Teste: {X_test.shape[0]} amostras")
    
    print(f"\n   üéØ SELE√á√ÉO AUTOM√ÅTICA DE FEATURES:")
    metodo_selecao = 'shap' if SHAP_AVAILABLE else 'rfe'
    X_train_selected, features_mask, feature_selector = selecionar_features_automatico(
        X_train, y_train, metodo=metodo_selecao
    )
    if feature_selector is not None and hasattr(feature_selector, 'transform'):
        X_test_selected = feature_selector.transform(X_test)
    elif metodo_selecao == 'shap' and features_mask is not None:
        if hasattr(X_test, 'iloc'):
            X_test_selected = X_test.iloc[:, features_mask]
        else:
            X_test_selected = X_test[:, features_mask]
    else:
        X_test_selected = X_test
    
    features_selecionadas = [features_disponiveis[i] for i, selected in enumerate(features_mask) if selected]
    print(f"   ‚úÖ Features selecionadas: {features_selecionadas}")
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train_selected)
    X_test_scaled = scaler.transform(X_test_selected)
    
    resultados_modelos = {}
    
    print(f"\n   üå≤ TREINANDO RANDOM FOREST:")
    try:
        rf_otimizado = otimizar_hiperparametros(X_train_scaled, y_train, 'random_forest')
        rf_otimizado.fit(X_train_scaled, y_train)
        
        y_train_pred_rf = rf_otimizado.predict(X_train_scaled)
        y_test_pred_rf = rf_otimizado.predict(X_test_scaled)
        
        mae_test_rf = mean_absolute_error(y_test, y_test_pred_rf)
        rmse_test_rf = np.sqrt(mean_squared_error(y_test, y_test_pred_rf))
        r2_test_rf = r2_score(y_test, y_test_pred_rf)
        mape_test_rf = np.mean(np.abs((y_test - y_test_pred_rf) / y_test)) * 100
        
        residuos_rf = analisar_residuos(y_test, y_test_pred_rf, "Random Forest")
        
        cv_results_temporal = validacao_cruzada_temporal(X_train_scaled, y_train, rf_otimizado)
        cv_results_estratificada = validacao_cruzada_estratificada(X_train_scaled, y_train, rf_otimizado)
        
        cv_results_rf = {
            'mae_mean': (cv_results_temporal['mae_mean'] + cv_results_estratificada['mae_mean']) / 2,
            'rmse_mean': (cv_results_temporal['rmse_mean'] + cv_results_estratificada['rmse_mean']) / 2,
            'r2_mean': (cv_results_temporal['r2_mean'] + cv_results_estratificada['r2_mean']) / 2,
            'mae_std': cv_results_estratificada['mae_std'],
            'rmse_std': cv_results_estratificada['rmse_std'],
            'r2_std': cv_results_estratificada['r2_std'],
            'temporal': cv_results_temporal,
            'estratificada': cv_results_estratificada
        }
        
        resultados_modelos['Random Forest'] = {
            'modelo': rf_otimizado,
            'mae_test': mae_test_rf,
            'rmse_test': rmse_test_rf,
            'r2_test': r2_test_rf,
            'mape_test': mape_test_rf,
            'residuos': residuos_rf,
            'cv_results': cv_results_rf,
            'feature_importance': pd.DataFrame({
                'Feature': features_selecionadas,
                'Importance': rf_otimizado.feature_importances_
            }).sort_values('Importance', ascending=False)
        }
        
        print(f"      ‚úÖ RF - MAE: R$ {mae_test_rf:.2f} | RMSE: R$ {rmse_test_rf:.2f} | R¬≤: {r2_test_rf:.4f}")
        
    except Exception as e:
        print(f"      ‚ùå Erro no Random Forest: {e}")
        logging.error(f"Erro no Random Forest: {e}")
    
    print(f"\n   üöÄ TREINANDO XGBOOST:")
    try:
        xgb_otimizado = otimizar_hiperparametros(X_train_scaled, y_train, 'xgboost')
        xgb_otimizado.fit(X_train_scaled, y_train)
        
        y_train_pred_xgb = xgb_otimizado.predict(X_train_scaled)
        y_test_pred_xgb = xgb_otimizado.predict(X_test_scaled)
        
        mae_test_xgb = mean_absolute_error(y_test, y_test_pred_xgb)
        rmse_test_xgb = np.sqrt(mean_squared_error(y_test, y_test_pred_xgb))
        r2_test_xgb = r2_score(y_test, y_test_pred_xgb)
        mape_test_xgb = np.mean(np.abs((y_test - y_test_pred_xgb) / y_test)) * 100
        
        residuos_xgb = analisar_residuos(y_test, y_test_pred_xgb, "XGBoost")
        
        cv_results_temporal = validacao_cruzada_temporal(X_train_scaled, y_train, xgb_otimizado)
        cv_results_estratificada = validacao_cruzada_estratificada(X_train_scaled, y_train, xgb_otimizado)
        
        cv_results_xgb = {
            'mae_mean': (cv_results_temporal['mae_mean'] + cv_results_estratificada['mae_mean']) / 2,
            'rmse_mean': (cv_results_temporal['rmse_mean'] + cv_results_estratificada['rmse_mean']) / 2,
            'r2_mean': (cv_results_temporal['r2_mean'] + cv_results_estratificada['r2_mean']) / 2,
            'mae_std': cv_results_estratificada['mae_std'],
            'rmse_std': cv_results_estratificada['rmse_std'],
            'r2_std': cv_results_estratificada['r2_std'],
            'temporal': cv_results_temporal,
            'estratificada': cv_results_estratificada
        }
        
        if hasattr(xgb_otimizado, 'feature_importances_'):
            feature_importance_xgb = pd.DataFrame({
                'Feature': features_selecionadas,
                'Importance': xgb_otimizado.feature_importances_
            }).sort_values('Importance', ascending=False)
        else:
            feature_importance_xgb = pd.DataFrame()
        
        resultados_modelos['XGBoost'] = {
            'modelo': xgb_otimizado,
            'mae_test': mae_test_xgb,
            'rmse_test': rmse_test_xgb,
            'r2_test': r2_test_xgb,
            'mape_test': mape_test_xgb,
            'residuos': residuos_xgb,
            'cv_results': cv_results_xgb,
            'feature_importance': feature_importance_xgb
        }
        
        print(f"      ‚úÖ XGB - MAE: R$ {mae_test_xgb:.2f} | RMSE: R$ {rmse_test_xgb:.2f} | R¬≤: {r2_test_xgb:.4f}")
        
    except Exception as e:
        print(f"      ‚ùå Erro no XGBoost: {e}")
        logging.error(f"Erro no XGBoost: {e}")
    
    print(f"\n   üìä COMPARA√á√ÉO DE MODELOS:")
    print("   " + "="*70)
    print("   MODELO          | MAE       | RMSE      | R¬≤      | MAPE     | CV R¬≤")
    print("   " + "="*70)
    
    melhor_modelo = None
    melhor_r2 = -np.inf
    
    for nome, resultado in resultados_modelos.items():
        cv_r2 = resultado['cv_results']['r2_mean']
        print(f"   {nome:<15} | R$ {resultado['mae_test']:6.2f} | R$ {resultado['rmse_test']:6.2f} | "
              f"{resultado['r2_test']:6.4f} | {resultado['mape_test']:6.2f}% | {cv_r2:6.4f}")
        
        if cv_r2 > melhor_r2:
            melhor_r2 = cv_r2
            melhor_modelo = nome
    
    print("   " + "="*70)
    print(f"   üèÜ MELHOR MODELO: {melhor_modelo} (CV R¬≤: {melhor_r2:.4f})")
    
    modelo_final = resultados_modelos[melhor_modelo]['modelo']
    metricas_final = {
        'mae_test': resultados_modelos[melhor_modelo]['mae_test'],
        'rmse_test': resultados_modelos[melhor_modelo]['rmse_test'],
        'r2_test': resultados_modelos[melhor_modelo]['r2_test'],
        'mape_test': resultados_modelos[melhor_modelo]['mape_test']
    }
    
    feature_importance_final = resultados_modelos[melhor_modelo]['feature_importance']
    
    print(f"\n   üéØ TOP 5 FEATURES MAIS IMPORTANTES ({melhor_modelo}):")
    if not feature_importance_final.empty:
        for i, row in feature_importance_final.head(5).iterrows():
            print(f"      {row['Feature']}: {row['Importance']:.4f}")
    
    logging.info(f"Melhor modelo selecionado: {melhor_modelo}")
    logging.info(f"M√©tricas finais: {metricas_final}")
    
    return (modelo_final, scaler, features_selecionadas, feature_importance_final, 
            metricas_final, resultados_modelos, feature_selector)

def treinar_modelo(df):
    """Fun√ß√£o wrapper para manter compatibilidade"""
    resultado = treinar_modelos_multiplos(df)
    return resultado[:5]


def calcular_confianca_predicao(modelo, X_sample_scaled, dados_categoria):
    """Calcula confian√ßa baseada na variabilidade das √°rvores e qualidade dos dados"""
    if hasattr(modelo, 'estimators_'):
        tree_predictions = [tree.predict(X_sample_scaled.reshape(1, -1))[0] 
                           for tree in modelo.estimators_]
        
        mean_pred = np.mean(tree_predictions)
        std_pred = np.std(tree_predictions)
        
        cv = std_pred / abs(mean_pred) if mean_pred != 0 else 1
        
        confianca_base = max(70, min(95, 100 * (1 - cv * 0.3)))
        
        return_predictions = tree_predictions
    
    else:
        prediction = modelo.predict(X_sample_scaled.reshape(1, -1))[0]
        
        variabilidade_mercado = dados_categoria['price'].std()
        media_mercado = dados_categoria['price'].mean()
        
        np.random.seed(42)
        noise_factor = min(0.1, variabilidade_mercado / media_mercado)
        simulated_predictions = []
        
        for _ in range(100):
            noise = np.random.normal(0, prediction * noise_factor)
            simulated_predictions.append(prediction + noise)
        
        variabilidade_relativa = variabilidade_mercado / media_mercado
        confianca_base = max(75, min(95, 100 * (1 - variabilidade_relativa * 0.5)))
        
        return_predictions = simulated_predictions
    
    num_registros = len(dados_categoria)
    num_vendedores = dados_categoria['seller_id'].nunique() if 'seller_id' in dados_categoria.columns else 1
    variabilidade_precos = dados_categoria['price'].std() / dados_categoria['price'].mean()
    
    if num_registros >= 100:
        confianca_base += 5
    elif num_registros >= 50:
        confianca_base += 3
    elif num_registros < 20:
        confianca_base -= 5
    
    if num_vendedores >= 10:
        confianca_base += 3
    elif num_vendedores >= 5:
        confianca_base += 2
    
    if variabilidade_precos > 1.0:
        confianca_base -= 3
    
    confianca_final = max(75, min(98, confianca_base))
    
    return confianca_final, return_predictions

def validar_e_ajustar_preco(preco_predito, dados_categoria):
    """Valida e ajusta o pre√ßo predito"""
    precos_mercado = dados_categoria['price']
    preco_min = precos_mercado.min()
    preco_max = precos_mercado.max()
    preco_mediano = precos_mercado.median()
    
    limite_inferior = preco_min * 0.6
    limite_superior = preco_max * 1.8
    
    preco_ajustado = preco_predito
    ajuste_aplicado = ""
    
    if preco_predito < limite_inferior:
        preco_ajustado = preco_min * 0.85
        ajuste_aplicado = f"Ajustado para cima: era R$ {preco_predito:.2f}, muito baixo"
    elif preco_predito > limite_superior:
        preco_ajustado = preco_max * 1.15
        ajuste_aplicado = f"Ajustado para baixo: era R$ {preco_predito:.2f}, muito alto"
    
    return preco_ajustado, ajuste_aplicado

def gerar_justificativas_especificas(categoria_nome, preco_recomendado, dados_categoria):
    """Gera justificativas espec√≠ficas e √∫nicas para cada categoria"""
    justificativas = []
    
    precos = dados_categoria['price']
    preco_min = precos.min()
    preco_max = precos.max()
    preco_medio = precos.mean()
    preco_mediano = precos.median()
    
    if preco_recomendado < preco_min:
        diferenca = ((preco_min - preco_recomendado) / preco_min * 100)
        justificativas.append(f"üí∞ Estrat√©gia agressiva: {diferenca:.0f}% abaixo do menor pre√ßo atual")
    elif preco_recomendado > preco_max:
        diferenca = ((preco_recomendado - preco_max) / preco_max * 100)
        justificativas.append(f"üíé Posicionamento premium: {diferenca:.0f}% acima do maior pre√ßo")
    elif preco_recomendado <= preco_mediano:
        diferenca = ((preco_mediano - preco_recomendado) / preco_mediano * 100)
        justificativas.append(f"‚ö° Competitivo: {diferenca:.0f}% abaixo da mediana")
    else:
        diferenca = ((preco_recomendado - preco_medio) / preco_medio * 100)
        justificativas.append(f"üìà Margem otimizada: {diferenca:.0f}% acima da m√©dia")
    
    categoria_lower = categoria_nome.lower()
    
    if 'informatica' in categoria_lower or 'telefonia' in categoria_lower:
        variabilidade = (preco_max - preco_min) / preco_medio * 100
        if variabilidade > 100:
            justificativas.append(f"üîß Tech: alta varia√ß√£o ({variabilidade:.0f}%) permite diferencia√ß√£o")
        else:
            justificativas.append("üîß Tech: mercado padronizado, pre√ßo competitivo necess√°rio")
    
    elif 'casa' in categoria_lower or 'moveis' in categoria_lower:
        peso_medio = dados_categoria['product_weight_g'].mean() if 'product_weight_g' in dados_categoria.columns else 0
        if peso_medio > 2000:
            justificativas.append(f"üè† M√≥veis: produto pesado ({peso_medio/1000:.1f}kg), frete alto")
        else:
            justificativas.append("üè† Casa: item decorativo, margem flex√≠vel")
    
    elif 'beleza' in categoria_lower or 'saude' in categoria_lower:
        nota_media = dados_categoria['review_score'].mean() if 'review_score' in dados_categoria.columns else 3.5
        if nota_media >= 4.2:
            justificativas.append(f"üíÑ Beleza: excelente reputa√ß√£o ({nota_media:.1f}‚òÖ)")
        else:
            justificativas.append(f"üíÑ Beleza: qualidade moderada ({nota_media:.1f}‚òÖ)")
    
    elif 'esporte' in categoria_lower:
        justificativas.append("üèÉ Esporte: mercado competitivo, pre√ßo √© fator decisivo")
    
    elif 'livros' in categoria_lower:
        justificativas.append("üìö Livros: margens baixas, volume √© importante")
    
    elif 'auto' in categoria_lower:
        justificativas.append("üöó Auto: compra t√©cnica, cliente pesquisa pre√ßos")
    
    else:
        num_vendedores = dados_categoria['seller_id'].nunique() if 'seller_id' in dados_categoria.columns else 1
        if num_vendedores >= 15:
            justificativas.append(f"üè™ Categoria disputada: {num_vendedores} vendedores")
        else:
            justificativas.append(f"üè™ Categoria concentrada: {num_vendedores} vendedores")
    
    if 'review_score' in dados_categoria.columns:
        nota_media = dados_categoria['review_score'].mean()
        num_reviews = dados_categoria['num_reviews'].mean() if 'num_reviews' in dados_categoria.columns else 0
        
        if nota_media >= 4.5:
            justificativas.append(f"‚≠ê Qualidade excepcional: {nota_media:.1f}‚òÖ de avalia√ß√£o")
        elif nota_media >= 4.0:
            justificativas.append(f"‚≠ê Boa qualidade: {nota_media:.1f}‚òÖ suporta o pre√ßo")
        elif nota_media < 3.5:
            justificativas.append(f"‚ö†Ô∏è Qualidade question√°vel: {nota_media:.1f}‚òÖ exige desconto")
    
    variabilidade_total = (preco_max - preco_min) / preco_medio * 100
    if variabilidade_total > 150:
        justificativas.append(f"üìä Mercado vol√°til: varia√ß√£o de {variabilidade_total:.0f}%")
    elif variabilidade_total < 50:
        justificativas.append("üìä Mercado est√°vel: pre√ßos padronizados")
    
    return justificativas[:4]


def analisar_produtos(df, modelo, scaler, features_disponiveis, feature_importance):
    """Analisa cada produto e gera recomenda√ß√µes"""
    print_section("AN√ÅLISE DE PRODUTOS E RECOMENDA√á√ïES")
    
    produtos_por_categoria = df.groupby('product_category_name').agg({
        'price': ['count', 'mean', 'min', 'max', 'std'],
        'review_score': 'mean',
        'product_id': 'nunique'
    }).round(2)
    
    produtos_por_categoria.columns = ['count', 'price_mean', 'price_min', 'price_max', 
                                    'price_std', 'review_mean', 'unique_products']
    produtos_por_categoria = produtos_por_categoria.reset_index()
    
    produtos_por_categoria = produtos_por_categoria[produtos_por_categoria['count'] >= 5]
    produtos_por_categoria = produtos_por_categoria.sort_values('count', ascending=False)
    
    print(f"   üìä Analisando {len(produtos_por_categoria)} categorias de produtos")
    
    resultados = []
    
    for idx, categoria_info in produtos_por_categoria.head(50).iterrows():
        categoria = categoria_info['product_category_name']
        
        print(f"\n{Colors.CYAN}üîç ANALISANDO: {Colors.YELLOW}{categoria.upper()}{Colors.RESET}")
        print(f"{Colors.BLUE}{'‚îÄ'*50}{Colors.RESET}")
        
        dados_categoria = df[df['product_category_name'] == categoria]
        
        print(f"   üì¶ Registros: {len(dados_categoria)}")
        print(f"   üè™ Vendedores: {dados_categoria['seller_id'].nunique() if 'seller_id' in dados_categoria.columns else 'N/A'}")
        
        precos_atuais = dados_categoria['price']
        print(f"   üí∞ Pre√ßos atuais:")
        print(f"      M√≠n: R$ {precos_atuais.min():.2f}")
        print(f"      M√°x: R$ {precos_atuais.max():.2f}")
        print(f"      M√©dio: R$ {precos_atuais.mean():.2f}")
        print(f"      Mediano: R$ {precos_atuais.median():.2f}")
        
        dados_medios = dados_categoria[features_disponiveis].mean()
        X_pred = dados_medios.values.reshape(1, -1)
        X_pred = np.nan_to_num(X_pred, nan=0.0)
        X_pred_scaled = scaler.transform(X_pred)
        
        preco_recomendado = modelo.predict(X_pred_scaled)[0]
        
        preco_final, ajuste_msg = validar_e_ajustar_preco(preco_recomendado, dados_categoria)
        
        if ajuste_msg:
            print(f"   ‚ö†Ô∏è {ajuste_msg}")
            preco_recomendado = preco_final
        
        confianca, tree_preds = calcular_confianca_predicao(modelo, X_pred_scaled, dados_categoria)
        
        variabilidade_predicao = np.std(tree_preds) if len(tree_preds) > 1 else 0.0
        
        justificativas = gerar_justificativas_especificas(categoria, preco_recomendado, dados_categoria)
        
        print(f"\n   üéØ RECOMENDA√á√ÉO:")
        print(f"      üíµ PRE√áO RECOMENDADO: R$ {preco_recomendado:.2f}")
        print(f"      üéØ CONFIAN√áA DA PREDI√á√ÉO: {confianca:.1f}%")
        print(f"      üìä Varia√ß√£o das predi√ß√µes: R$ {variabilidade_predicao:.2f}")
        
        print(f"\n   üìã JUSTIFICATIVAS:")
        for i, justificativa in enumerate(justificativas, 1):
            print(f"      {i}. {justificativa}")
        
        diferenca_min = preco_recomendado - precos_atuais.min()
        diferenca_max = preco_recomendado - precos_atuais.max()
        diferenca_media = preco_recomendado - precos_atuais.mean()
        
        print(f"\n   üìà COMPARA√á√ÉO COM MERCADO:")
        print(f"      vs Menor pre√ßo: {diferenca_min:+.2f} R$")
        print(f"      vs Maior pre√ßo: {diferenca_max:+.2f} R$")
        print(f"      vs Pre√ßo m√©dio: {diferenca_media:+.2f} R$")
        
        resultado = {
            'Produto': categoria,
            'Pre√ßo_Recomendado': preco_recomendado,
            'Confian√ßa_Predi√ß√£o': confianca,
            'Pre√ßo_Min_Mercado': precos_atuais.min(),
            'Pre√ßo_Max_Mercado': precos_atuais.max(),
            'Pre√ßo_M√©dio_Mercado': precos_atuais.mean(),
            'Pre√ßo_Mediano_Mercado': precos_atuais.median(),
            'Diferen√ßa_vs_M√©dia': diferenca_media,
            'Variabilidade_√Årvores': variabilidade_predicao,
            'Justificativas': justificativas,
            'Registros_Mercado': len(dados_categoria),
            'Vendedores_√önicos': dados_categoria['seller_id'].nunique() if 'seller_id' in dados_categoria.columns else 1
        }
        
        resultados.append(resultado)
    
    return resultados


def criar_visualizacoes(resultados, metricas_modelo):
    """Cria visualiza√ß√µes interativas dos resultados com an√°lise detalhada"""
    print_section("CRIANDO VISUALIZA√á√ïES INTERATIVAS")
    
    if not resultados:
        print("   ‚ùå Nenhum resultado para visualizar")
        return
    
    df_resultados = pd.DataFrame(resultados)
    
    produtos_detalhados = []
    for _, row in df_resultados.iterrows():
        justificativas_texto = "<br>".join([f"‚Ä¢ {j}" for j in row['Justificativas']])
        
        produto_info = {
            'Produto': row['Produto'],
            'Pre√ßo_Anterior': row['Pre√ßo_M√©dio_Mercado'],
            'Pre√ßo_ML': row['Pre√ßo_Recomendado'],
            'Mudan√ßa_Percentual': ((row['Pre√ßo_Recomendado'] - row['Pre√ßo_M√©dio_Mercado']) / row['Pre√ßo_M√©dio_Mercado'] * 100),
            'Confian√ßa': row['Confian√ßa_Predi√ß√£o'],
            'Fatores_Considerados': justificativas_texto,
            'Variabilidade': row['Variabilidade_√Årvores'],
            'Faixa_Min': row['Pre√ßo_Min_Mercado'],
            'Faixa_Max': row['Pre√ßo_Max_Mercado'],
            'Registros': row['Registros_Mercado'],
            'Vendedores': row['Vendedores_√önicos']
        }
        produtos_detalhados.append(produto_info)
    
    df_detalhado = pd.DataFrame(produtos_detalhados)
    
    fig_principal = go.Figure()
    
    fig_principal.add_trace(go.Bar(
        name='Pre√ßo M√©dio Atual (Mercado)',
        x=df_detalhado['Produto'],
        y=df_detalhado['Pre√ßo_Anterior'],
        marker_color='lightblue',
        opacity=0.7,
        text=[f'R$ {p:.2f}' for p in df_detalhado['Pre√ßo_Anterior']],
        textposition='outside',
        hovertemplate='<b>%{x}</b><br>' +
                     'Pre√ßo M√©dio Mercado: R$ %{y:.2f}<br>' +
                     '<extra></extra>'
    ))
    
    fig_principal.add_trace(go.Bar(
        name='Pre√ßo Recomendado (ML)',
        x=df_detalhado['Produto'],
        y=df_detalhado['Pre√ßo_ML'],
        marker_color='darkgreen',
        opacity=0.9,
        text=[f'R$ {p:.2f}' for p in df_detalhado['Pre√ßo_ML']],
        textposition='outside',
        hovertemplate='<b>%{x}</b><br>' +
                     'Pre√ßo ML: R$ %{y:.2f}<br>' +
                     'Confian√ßa: %{customdata[0]:.1f}%<br>' +
                     'Mudan√ßa: %{customdata[1]:+.1f}%<br>' +
                     '<b>Fatores Considerados:</b><br>%{customdata[2]}<br>' +
                     '<extra></extra>',
        customdata=list(zip(df_detalhado['Confian√ßa'], 
                           df_detalhado['Mudan√ßa_Percentual'],
                           df_detalhado['Fatores_Considerados']))
    ))
    
    fig_principal.add_trace(go.Scatter(
        name='Faixa M√≠n-M√°x do Mercado',
        x=df_detalhado['Produto'],
        y=df_detalhado['Faixa_Min'],
        mode='markers',
        marker=dict(color='red', size=8, symbol='triangle-down'),
        showlegend=False,
        hovertemplate='Pre√ßo M√≠nimo: R$ %{y:.2f}<extra></extra>'
    ))
    
    fig_principal.add_trace(go.Scatter(
        name='Faixa M√≠n-M√°x do Mercado',
        x=df_detalhado['Produto'],
        y=df_detalhado['Faixa_Max'],
        mode='markers',
        marker=dict(color='red', size=8, symbol='triangle-up'),
        hovertemplate='Pre√ßo M√°ximo: R$ %{y:.2f}<extra></extra>'
    ))
    
    fig_principal.update_layout(
        title={
            'text': 'An√°lise de Pre√ßos: Mercado Atual vs Recomenda√ß√µes do Machine Learning<br>' +
                   '<sub>Hover sobre as barras verdes para ver fatores considerados e taxa de confian√ßa</sub>',
            'x': 0.5,
            'font': {'size': 16}
        },
        xaxis_title='Produtos',
        yaxis_title='Pre√ßo (R$)',
        height=700,
        width=1400,
        showlegend=True,
        legend=dict(x=0.02, y=0.98),
        hovermode='closest'
    )
    
    fig_principal.update_xaxes(tickangle=45)
    
    fig_principal.write_html("analise_precos_principal.html")
    print(f"   üìä Gr√°fico principal salvo em: analise_precos_principal.html")
    
    fig_dashboard = make_subplots(
        rows=2, cols=3,
        subplot_titles=[
            'Taxa de Confian√ßa por Produto',
            'Mudan√ßa Percentual nos Pre√ßos',
            'Variabilidade das Predi√ß√µes',
            'An√°lise de Qualidade dos Dados',
            'Impacto Financeiro',
            'Performance do Modelo ML'
        ],
        specs=[[{"secondary_y": False}, {"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}, {"secondary_y": False}]],
        vertical_spacing=0.15,
        horizontal_spacing=0.1
    )
    
    produtos_curtos = [p[:12] + '...' if len(p) > 12 else p for p in df_detalhado['Produto']]
    
    colors_confianca = ['#2E8B57' if x >= 90 else '#FF8C00' if x >= 85 else '#DC143C' 
                       for x in df_detalhado['Confian√ßa']]
    fig_dashboard.add_trace(
        go.Bar(name='Confian√ßa', x=produtos_curtos, y=df_detalhado['Confian√ßa'],
               marker_color=colors_confianca, opacity=0.8, showlegend=False,
               text=[f'{c:.1f}%' for c in df_detalhado['Confian√ßa']],
               textposition='outside',
               hovertemplate='%{x}<br>Confian√ßa: %{y:.1f}%<extra></extra>'),
        row=1, col=1
    )
    
    colors_mudanca = ['#2E8B57' if x > 0 else '#DC143C' if x < -5 else '#FF8C00' 
                     for x in df_detalhado['Mudan√ßa_Percentual']]
    fig_dashboard.add_trace(
        go.Bar(name='Mudan√ßa', x=produtos_curtos, y=df_detalhado['Mudan√ßa_Percentual'],
               marker_color=colors_mudanca, opacity=0.8, showlegend=False,
               text=[f'{m:+.1f}%' for m in df_detalhado['Mudan√ßa_Percentual']],
               textposition='outside',
               hovertemplate='%{x}<br>Mudan√ßa: %{y:+.1f}%<extra></extra>'),
        row=1, col=2
    )
    
    fig_dashboard.add_trace(
        go.Bar(name='Variabilidade', x=produtos_curtos, y=df_detalhado['Variabilidade'],
               marker_color='purple', opacity=0.7, showlegend=False,
               text=[f'R${v:.2f}' for v in df_detalhado['Variabilidade']],
               textposition='outside',
               hovertemplate='%{x}<br>Variabilidade: R$ %{y:.2f}<extra></extra>'),
        row=1, col=3
    )
    
    fig_dashboard.add_trace(
        go.Scatter(x=df_detalhado['Registros'], y=df_detalhado['Vendedores'],
                  mode='markers+text', 
                  marker=dict(size=[r/20 for r in df_detalhado['Registros']], 
                            color=df_detalhado['Confian√ßa'],
                            colorscale='RdYlGn', 
                            showscale=False,
                            line=dict(width=1, color='black')),
                  text=produtos_curtos,
                  textposition="middle center",
                  showlegend=False,
                  hovertemplate='%{text}<br>Registros: %{x}<br>Vendedores: %{y}<extra></extra>'),
        row=2, col=1
    )
    
    impacto_financeiro = df_detalhado['Mudan√ßa_Percentual'] * df_detalhado['Pre√ßo_Anterior'] / 100
    colors_impacto = ['#2E8B57' if x > 0 else '#DC143C' for x in impacto_financeiro]
    fig_dashboard.add_trace(
        go.Bar(name='Impacto', x=produtos_curtos, y=impacto_financeiro,
               marker_color=colors_impacto, opacity=0.8, showlegend=False,
               text=[f'R${i:+.2f}' for i in impacto_financeiro],
               textposition='outside',
               hovertemplate='%{x}<br>Impacto: R$ %{y:+.2f}<extra></extra>'),
        row=2, col=2
    )
    
    metricas_nomes = ['MAE\n(R$)', 'RMSE\n(R$)', 'R¬≤', 'MAPE\n(%)']
    metricas_valores = [
        metricas_modelo['mae_test'],
        metricas_modelo['rmse_test'],
        metricas_modelo['r2_test'],
        metricas_modelo['mape_test']
    ]
    
    fig_dashboard.add_trace(
        go.Bar(name='M√©tricas', x=metricas_nomes, y=metricas_valores,
               marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'], 
               opacity=0.8, showlegend=False,
               text=[f'{m:.3f}' if m < 1 else f'{m:.1f}' for m in metricas_valores],
               textposition='outside',
               hovertemplate='%{x}: %{y}<extra></extra>'),
        row=2, col=3
    )
    
    fig_dashboard.update_layout(
        height=900,
        width=1500,
        title_text="Dashboard Detalhado de An√°lise de Pre√ßos com Machine Learning",
        title_x=0.5,
        showlegend=False
    )
    
    fig_dashboard.update_xaxes(tickangle=45, row=1, col=1)
    fig_dashboard.update_xaxes(tickangle=45, row=1, col=2)
    fig_dashboard.update_xaxes(tickangle=45, row=1, col=3)
    fig_dashboard.update_xaxes(title_text="N¬∫ de Registros", row=2, col=1)
    fig_dashboard.update_xaxes(tickangle=45, row=2, col=2)
    fig_dashboard.update_xaxes(tickangle=30, row=2, col=3)
    
    fig_dashboard.update_yaxes(title_text="Confian√ßa (%)", row=1, col=1)
    fig_dashboard.update_yaxes(title_text="Mudan√ßa (%)", row=1, col=2)
    fig_dashboard.update_yaxes(title_text="Variabilidade (R$)", row=1, col=3)
    fig_dashboard.update_yaxes(title_text="N¬∫ de Vendedores", row=2, col=1)
    fig_dashboard.update_yaxes(title_text="Impacto (R$)", row=2, col=2)
    fig_dashboard.update_yaxes(title_text="Valor", row=2, col=3)
    
    fig_dashboard.write_html("dashboard_analise_detalhada.html")
    print(f"   üìä Dashboard salvo em: dashboard_analise_detalhada.html")
    
    fig_scatter = go.Figure()
    
    fig_scatter.add_trace(go.Scatter(
        x=df_detalhado['Confian√ßa'],
        y=df_detalhado['Mudan√ßa_Percentual'],
        mode='markers+text',
        marker=dict(
            size=[abs(i)*2 + 10 for i in impacto_financeiro],
            color=df_detalhado['Variabilidade'],
            colorscale='Viridis',
            showscale=True,
            colorbar=dict(title="Variabilidade<br>(R$)"),
            line=dict(width=2, color='black')
        ),
        text=produtos_curtos,
        textposition="middle center",
        hovertemplate='<b>%{text}</b><br>' +
                     'Confian√ßa: %{x:.1f}%<br>' +
                     'Mudan√ßa: %{y:+.1f}%<br>' +
                     'Impacto: R$ %{customdata:+.2f}<br>' +
                     '<extra></extra>',
        customdata=impacto_financeiro
    ))
    
    fig_scatter.add_hline(y=0, line_dash="dash", line_color="gray", 
                         annotation_text="Sem mudan√ßa de pre√ßo")
    fig_scatter.add_vline(x=85, line_dash="dash", line_color="orange", 
                         annotation_text="Confian√ßa m√≠nima recomendada")
    
    fig_scatter.update_layout(
        title='An√°lise de Risco vs Retorno: Confian√ßa √ó Mudan√ßa de Pre√ßos<br>' +
              '<sub>Tamanho das bolhas = impacto financeiro | Cor = variabilidade da predi√ß√£o</sub>',
        xaxis_title='Taxa de Confian√ßa (%)',
        yaxis_title='Mudan√ßa Percentual no Pre√ßo (%)',
        height=600,
        width=1200,
        hovermode='closest'
    )
    
    fig_scatter.write_html("analise_risco_retorno.html")
    print(f"   üìä An√°lise risco vs retorno salva em: analise_risco_retorno.html")
    
    print(f"\n{Colors.GREEN}‚úÖ Visualiza√ß√µes interativas criadas com sucesso!{Colors.RESET}")
    print(f"   üìä 3 gr√°ficos HTML gerados:")
    print(f"      1. analise_precos_principal.html - Compara√ß√£o detalhada Antes vs Depois")
    print(f"      2. dashboard_analise_detalhada.html - Dashboard de an√°lise completa") 
    print(f"      3. analise_risco_retorno.html - An√°lise de risco vs retorno")
    print(f"\n{Colors.CYAN}üí° Para visualizar os gr√°ficos, abra os arquivos HTML no seu navegador!{Colors.RESET}")

def documentar_limitacoes_modelo():
    """Documenta limita√ß√µes e considera√ß√µes importantes do modelo"""
    print_section("LIMITA√á√ïES E CONSIDERA√á√ïES DO MODELO")
    
    limitacoes = [
        "üìä LIMITA√á√ïES DOS DADOS:",
        "   ‚Ä¢ Dados hist√≥ricos podem n√£o refletir tend√™ncias futuras",
        "   ‚Ä¢ Sazonalidade pode variar entre diferentes per√≠odos",
        "   ‚Ä¢ Novos produtos sem hist√≥rico t√™m predi√ß√µes menos confi√°veis",
        "",
        "ü§ñ LIMITA√á√ïES DO MODELO:",
        "   ‚Ä¢ Modelo assume que padr√µes hist√≥ricos continuar√£o v√°lidos",
        "   ‚Ä¢ Features categ√≥ricas podem n√£o capturar todas as nuances",
        "   ‚Ä¢ Outliers extremos podem afetar predi√ß√µes mesmo com tratamento",
        "",
        "üíº CONSIDERA√á√ïES DE NEG√ìCIO:",
        "   ‚Ä¢ Pre√ßos devem ser validados por especialistas de dom√≠nio",
        "   ‚Ä¢ Fatores externos (economia, concorr√™ncia) n√£o s√£o considerados",
        "   ‚Ä¢ Recomenda√ß√µes devem ser testadas em pequena escala primeiro",
        "",
        "üîÑ RECOMENDA√á√ïES DE USO:",
        "   ‚Ä¢ Re-treinar modelo mensalmente com dados atualizados",
        "   ‚Ä¢ Monitorar performance das predi√ß√µes em produ√ß√£o",
        "   ‚Ä¢ Combinar com an√°lise de especialistas de pricing",
        "   ‚Ä¢ Usar intervalos de confian√ßa para decis√µes de risco"
    ]
    
    for limitacao in limitacoes:
        print(f"   {limitacao}")
    
    logging.info("Limita√ß√µes do modelo documentadas")

def mostrar_resumo_final(resultados, metricas_modelo):
    """Mostra resumo executivo final"""
    print_header("RESUMO EXECUTIVO FINAL")
    
    if not resultados:
        print(f"{Colors.RED}‚ùå Nenhum resultado para mostrar{Colors.RESET}")
        return
    
    df_final = pd.DataFrame(resultados)
    
    print(f"{Colors.GREEN}üìä RESUMO GERAL:{Colors.RESET}")
    print(f"   üéØ Produtos analisados: {len(df_final)}")
    print(f"   üìà Confian√ßa m√©dia: {df_final['Confian√ßa_Predi√ß√£o'].mean():.1f}%")
    print(f"   üí∞ Pre√ßo m√©dio recomendado: R$ {df_final['Pre√ßo_Recomendado'].mean():.2f}")
    print(f"   üìä R¬≤ do modelo: {metricas_modelo['r2_test']:.4f}")
    print(f"   üéØ MAPE: {metricas_modelo['mape_test']:.2f}%")
    
    print(f"\n{Colors.YELLOW}üèÜ RESULTADOS FINAIS:{Colors.RESET}")
    print("‚îÄ" * 95)
    print(f"{'PRODUTO':<40} | {'PRE√áO REC.':<12} | {'CONFIAN√áA':<10} | {'vs M√âDIA MERCADO':<15}")
    print("‚îÄ" * 95)
    
    for _, row in df_final.iterrows():
        conf_icon = "üü¢" if row['Confian√ßa_Predi√ß√£o'] >= 90 else "üü°" if row['Confian√ßa_Predi√ß√£o'] >= 80 else "üî¥"
        diferenca = row['Pre√ßo_Recomendado'] - row['Pre√ßo_M√©dio_Mercado']
        
        produto_nome = row['Produto'][:37] + "..." if len(row['Produto']) > 37 else row['Produto']
        
        print(f"{conf_icon} {produto_nome:<37} | R$ {row['Pre√ßo_Recomendado']:8.2f} | "
              f"{row['Confian√ßa_Predi√ß√£o']:6.1f}% | {diferenca:+8.2f}")
    
    print("‚îÄ" * 95)
    
    alta_conf = len(df_final[df_final['Confian√ßa_Predi√ß√£o'] >= 90])
    media_conf = len(df_final[(df_final['Confian√ßa_Predi√ß√£o'] >= 80) & 
                             (df_final['Confian√ßa_Predi√ß√£o'] < 90)])
    baixa_conf = len(df_final[df_final['Confian√ßa_Predi√ß√£o'] < 80])
    
    print(f"\n{Colors.GREEN}üéØ AN√ÅLISE DE CONFIAN√áA:{Colors.RESET}")
    print(f"   üü¢ Alta confian√ßa (‚â•90%): {alta_conf} produtos")
    print(f"   üü° M√©dia confian√ßa (80-89%): {media_conf} produtos")
    print(f"   üî¥ Baixa confian√ßa (<80%): {baixa_conf} produtos")
    
    top_10 = df_final.nlargest(10, 'Confian√ßa_Predi√ß√£o')
    print(f"\n{Colors.CYAN}üèÜ TOP 10 RECOMENDA√á√ïES (por confian√ßa):{Colors.RESET}")
    for i, (_, row) in enumerate(top_10.iterrows(), 1):
        print(f"   {i}. {row['Produto']}")
        print(f"      üí∞ Pre√ßo: R$ {row['Pre√ßo_Recomendado']:.2f}")
        print(f"      üéØ Confian√ßa: {row['Confian√ßa_Predi√ß√£o']:.1f}%")
        print(f"      üìä Diferen√ßa vs mercado: {row['Diferen√ßa_vs_M√©dia']:+.2f} R$")
        if row['Justificativas']:
            print(f"      üìã Justificativa: {row['Justificativas'][0]}")
        print()


def main():
    """Fun√ß√£o principal do sistema"""
    print_header("SISTEMA DE RECOMENDA√á√ÉO DE PRE√áOS - OLIST E-COMMERCE")
    
    try:
        datasets = carregar_dados(usar_kaggle=True)
        if not datasets:
            return
        
        df_main = juntar_datasets(datasets)
        
        df_clean = limpar_dados(df_main)
        
        df_features, le_category, le_customer_state, le_seller_state = engenharia_features(df_clean)
        
        resultado_completo = treinar_modelos_multiplos(df_features)
        modelo, scaler, features_disponiveis, feature_importance, metricas = resultado_completo[:5]
        
        salvar_dados_referencia(df_features[features_disponiveis])
        
        retreinamento = ModeloRetreinamento()
        retreinamento.salvar_modelo(
            modelo, scaler, features_disponiveis, 
            metadata={'metricas': metricas, 'feature_importance': feature_importance.to_dict() if hasattr(feature_importance, 'to_dict') else {}}
        )
        
        resultados = analisar_produtos(df_features, modelo, scaler, 
                                     features_disponiveis, feature_importance)
        
        criar_visualizacoes(resultados, metricas)
        
        documentar_limitacoes_modelo()
        
        mostrar_resumo_final(resultados, metricas)
        
        print_header("AN√ÅLISE CONCLU√çDA COM SUCESSO!")
        
    except Exception as e:
        print(f"{Colors.RED}‚ùå Erro durante a execu√ß√£o: {e}{Colors.RESET}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()